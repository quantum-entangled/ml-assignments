{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation using Recurrent Neural Networks\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recurrent neural networks (RNNs) have emerged as powerful predictive and generative models for a range of applications. For example, take a look at the excellent blog post by Andrew Karpathy on [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). In this exercise, your task is to build a generative, character-by-character RNN that can predict the next character from a given sequence. The classic work *The Odyssey* by Homer will serve as a corpus for your model. An example of the type of text that you can generate from this lab is below. The `seed` text represents an initial sequence of characters that is randomly sampled from the corpus. Following the seed, you can see that the model has predicted a fairly realistic text sequence, in the style of the *The Odyssey*, including realistic line breaks and punctuation.\n",
    "\n",
    "<b>Seed text</b>\n",
    "```\n",
    "h ulysses for having\n",
    "blinded an eye of p\n",
    "```\n",
    "\n",
    "<b>Prediction of next 500 characters</b>\n",
    "```\n",
    "olypels end she darte yod mentered saw he would polden ewall by sur; for her got him eather, and he would send\n",
    "them flying out of the hould not save his\n",
    "men, for they perished through their own sheer folly in eating the\n",
    "cattle of the sun-god hyperion; so the god prevented them from ever\n",
    "reaching home. tell me, too, about all these things, oh daughter of\n",
    "jove, from whatsoever source you may know them.\n",
    "\n",
    "so now all who escaped death in battle or by shipwreck had got safely\n",
    "home except ulysses, and \n",
    "```\n",
    "\n",
    "### RNN Models in Keras\n",
    "\n",
    "As in the CNN exercise, we will use the Tensorflow Keras module to implement a simple RNN model. Specifically, we will make use of the [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) and [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) layers.\n",
    "Before proceeding, it may be useful to familiarize yourself with the [Keras API for RNNs](https://www.tensorflow.org/guide/keras/rnn). In particular, understanding what input shape each RNN layer expects will be crucial.\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "In essence, an embedding encodes an integer index as a vector of some size. You may think of this as a generalization of a one-hot encodding. For example, consider the list of characters in the word \"hello\". If this word contained all the characters in our vocabulary (namely \"h\", \"e\", \"l\", and \"o\"), we can generate a one-hot encoding where each character is represented by a vector of size 4, with a 1 in the element corresponding to the letter, and zeros everwhere else. For our 4-character vocabulary, this could look like the following:\n",
    "\n",
    "| char / index | encodding  |\n",
    "|--------------|------------|\n",
    "|h / 0         | 1 0 0 0    |\n",
    "|e / 1         | 0 1 0 0    |\n",
    "|l / 2         | 0 0 1 0    |\n",
    "|o / 3         | 0 0 0 1    |\n",
    "\n",
    "While one-hot encoddings are usefull for many applications, they have a number of limitations. For example,\n",
    "\n",
    "- The encodding matrix is extremely sparse\n",
    "- The size of the encodding depends on the size of the vocabulary or number of categories being encodded\n",
    "- There is no notion of similarity between the entities being encodded\n",
    "\n",
    "An embedding solves these problems by using a learnable (size of vocabulary)X(size of encodding) matrix, in place of the fixed and sparse one-hot encodding matrix. Continuing with our previous example, an embedding for the characters in \"hello\" might take the form\n",
    "\n",
    "| char / index | encodding   |\n",
    "|--------------|-------------|\n",
    "|h / 0         | 1.2 0.3 4.3 |\n",
    "|e / 1         | 0.1 1.5 7.8 |\n",
    "|l / 2         | 0.5 3.2 1.9 |\n",
    "|o / 3         | 3.6 7.2 5.8 |\n",
    "\n",
    "Note that here, we have chosen an encoding represented by a vector of size 3, which is less than the size of the vocabulary. This is called \"embedding\" our vocabulary in a 3 dimensional space. This is extremely useful when building encoddings for very large vocabularies. In addition, the coefficients in the encodding matrix are learned during the training process, allowing \"similar\" characters (in this case) to be grouped locally in the encodding space. Further, we can visualize the embedding space through a number of techniques to help us understand how our vocabulary is encodded. We will not do that here, but you can find a number of examples online, if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Import packages and intialize various global variables. You may want to change these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "window_size = 40 # length of character sequences\n",
    "batch_size = 32 # batch size for learning\n",
    "rnn_units = 128 # number of hidden units in the LSTM or GRU cells cell\n",
    "epochs = 100 # number of training epochs\n",
    "\n",
    "corpus_file = 'odyssey.txt'\n",
    "\n",
    "\n",
    "def load_corpus(file_name, local=True, github_repo='/'):\n",
    "    \"\"\"Loads the corpus text from a given file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        If local is True, the full path to the local file, otherwise the file name for the github repo.\n",
    "    local : bool\n",
    "        True if file is local, False (default) if file is in github repo.\n",
    "    github_repo : str\n",
    "        Github repo storing the file (only used if local is False).\n",
    "    \"\"\"\n",
    "    # Open local file\n",
    "    if local:\n",
    "        return open(file_name, 'r').read()\n",
    "    \n",
    "    # Get file from repository\n",
    "    page = requests.get(f'https://raw.githubusercontent.com/{github_repo}/{file_name}')\n",
    "    \n",
    "    return page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Preprocess text data\n",
    "\n",
    "Fill in the function below to read in the text file given by `text_file` and perform any preprocessing that you feel is necessary. For example, convert the text to lower case in order to reduce the size of the vocabulary. Other examples of processing include replacing accented characters with non accented characters, removing \"unnecessary\" punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the odyssey\n",
      "\n",
      "\n",
      "book i\n",
      "\n",
      "the gods in councilminervas visit to ithacathe challenge from\n",
      "telemachus tosuitors.\n",
      "\n",
      "tell me, o muse, of that ingenious hero who travelled far and wide after\n",
      "he had sackedfamous town of troy. many cities did he visit, and\n",
      "many werenations with whose manners and customs he was acquainted;\n",
      "moreover he suffered much by sea while trying to save his own life and\n",
      "bring his men safely home; but do what he might he could not save his\n",
      "men, for they perished through their own sheer f\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_file(file_name):\n",
    "    \"\"\"Read a text file, perform preprocessing, and return text as a string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Name of text file to load.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        Preprocessed text from the file.\n",
    "    \"\"\"\n",
    "    # Read in file (using load_corpus()) and convert to lower case\n",
    "    text = load_corpus(file_name).lower()\n",
    "\n",
    "    # Perform additional processing\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate({ord(c): None for c in '!@#$\"{-}:'\"'\"})\n",
    "    text = text.replace(' the ', '')\n",
    "    text = text.strip()\n",
    "    text = re.sub(' {2,}', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load and prepare data\n",
    "text = preprocess_file(corpus_file)\n",
    "\n",
    "# Shorten text for testing\n",
    "text = text[:10000]\n",
    "print(text[:500])\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Generate a dataset for training\n",
    "\n",
    "Fill in the function below which takes in the document text and a \"window\" size and returns a list of unique characters representing the vocabulary for the document as well as the training data. The training data consists of two lists. The first is a list of lists of integers (indexing the vocabulary list) corresponding to a sequences of characters found in the document of length `window_size`. The other is a list of integers (indexing the vocabulary list) corresponding to the next character in the sequence, for each sequence in the first list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['\\n', ' ', ',', '.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocabulary length: 32.\n",
      "\n",
      "First element of X_data: [25, 13, 10, 1, 20, 9, 30, 24, 24, 10, 30, 0, 0, 0, 7, 20, 20, 16, 1, 14, 0, 0, 25, 13, 10, 1, 12, 20, 9, 24, 1, 14, 19, 1, 8, 20, 26, 19, 8, 14]\n",
      "Text length: 10000.\n",
      "X_data length: 9960.\n",
      "\n",
      "First element of y_data: 17.\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(text, window_size=40):\n",
    "    \"\"\"Create the dataset used to train the RNN.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        String representing text to learn on.\n",
    "    window_size : int\n",
    "        Length of character sequence used to predict next character.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    vocab : list(char)\n",
    "        List of characters making up the vocabulary of the text.\n",
    "    x_data : list(list(int))\n",
    "        List of sequences of size window_size, containing indices into vocab.\n",
    "        Each sequence represents a sequence of window_size characters found in\n",
    "        the text. The number of sequences generated will be len(text) - window_size.\n",
    "    y_data : list(int)\n",
    "        List of indices corresponding to the characters that follow the\n",
    "        sequences in x_data.\n",
    "    \"\"\"\n",
    "    # Determine list of unique characters\n",
    "    vocab = sorted(list(set(text)))\n",
    "\n",
    "    # Generate training data\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for i in range(len(text)-window_size):\n",
    "        X_tmp = []\n",
    "\n",
    "        for char in text[i:i+window_size]:\n",
    "            X_tmp.append(vocab.index(char))\n",
    "\n",
    "        X_data.append(X_tmp)\n",
    "        y_data.append(vocab.index(text[i+window_size]))\n",
    "    \n",
    "    return X_data, y_data, vocab\n",
    "\n",
    "\n",
    "# Retrieve training data\n",
    "X_data, y_data, vocab = make_dataset(text, window_size=window_size)\n",
    "\n",
    "# Check if everything is working\n",
    "print(f\"Vocabulary: {vocab}\")\n",
    "print(f\"Vocabulary length: {len(vocab)}.\\n\")\n",
    "print(f\"First element of X_data: {X_data[0]}\")\n",
    "print(f\"Text length: {len(text)}.\")\n",
    "print(f\"X_data length: {len(X_data)}.\\n\")\n",
    "print(f\"First element of y_data: {y_data[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create the RNN model\n",
    "\n",
    "Fill in the function below which builds and returns the RNN model, for the given size parameters and RNN layer. The model should take as input a tensor representing batches of character index sequences and output a tensor representing the probabilities of each character in the vocabulary coming next in the sequence, for each sequence in the batch. Use the following architecture.  \n",
    "\n",
    "- Sequential Keras model\n",
    "  - [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) with input and output dimensions equal to the vocab size (you can try using smaller encoddings later)\n",
    "  - [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) with num_units\n",
    "  - [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) output, with softmax\n",
    "- `sparse_categorical_crossentropy` loss\n",
    "- Adam optimizer\n",
    "- Metrics: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(num_units, window_size, vocab_size, rnn_layer=layers.LSTM):\n",
    "    \"\"\"Creates the RNN model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_units : int\n",
    "        Number of hidden units in the LSTM layer.\n",
    "    window_size : int\n",
    "        Number of characters in an input sequence.\n",
    "    vocab_size : int\n",
    "        Number of unique characters in the vocabulary.\n",
    "    rnn_layer : Keras RNN layer (RNN, LSTM, GRU)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : Keras model\n",
    "        RNN model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize model object\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=vocab_size, \n",
    "        trainable=True, input_length=window_size))\n",
    "    model.add(rnn_layer(num_units, return_sequences=False))\n",
    "    model.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 32)            1024      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               62208     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,360\n",
      "Trainable params: 67,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = rnn_model(rnn_units, window_size, len(vocab), layers.GRU)\n",
    "\n",
    "# Print summary of compiled model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Train and evaluate\n",
    "\n",
    "Fill in the code below to train the RNN model. After every 3 epochs, generate 500 characters of text from a random seed sequence to gauge how well the model is doing. This can be done by using the seed to predict the next character in the sequence (take the maximum likelihood character). Append this new character onto the sequence (dropping the first character to maintain the window size) and repeat. Print each new character as you go to generate the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "312/312 [==============================] - 14s 34ms/step - loss: 2.7956 - accuracy: 0.2107\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 2.3826 - accuracy: 0.2999\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 2.2815 - accuracy: 0.3215\n",
      "Generated text after 3 epochs of training:\n",
      "\n",
      " for them.\n",
      "\n",
      "thensuitors came in and took he and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and a\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 2.2036 - accuracy: 0.3421\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 30s 97ms/step - loss: 2.1260 - accuracy: 0.3616\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 9s 29ms/step - loss: 2.0419 - accuracy: 0.3845\n",
      "Generated text after 6 epochs of training:\n",
      "\n",
      " longer heed them; we shall never see him he theme them men the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the mand the \n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 1.9621 - accuracy: 0.4102\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 1.8830 - accuracy: 0.4349\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 1.8042 - accuracy: 0.4581\n",
      "Generated text after 9 epochs of training:\n",
      "\n",
      "  we have made up our minds and\n",
      "that he in and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for he wand of and with when them for\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 8s 24ms/step - loss: 1.7261 - accuracy: 0.4736\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 8s 24ms/step - loss: 1.6511 - accuracy: 0.4959\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 1.5763 - accuracy: 0.5196\n",
      "Generated text after 12 epochs of training:\n",
      "\n",
      " uld not save his\n",
      "men, for they perished them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for them them for t\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 8s 25ms/step - loss: 1.5024 - accuracy: 0.5420\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 1.4280 - accuracy: 0.5655\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 1.3554 - accuracy: 0.5848\n",
      "Generated text after 15 epochs of training:\n",
      "\n",
      " use,carver\n",
      "fetched them plates of all mane on a spear and seaven he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was against him got him got he was aga\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 1.2838 - accuracy: 0.6095\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 1.2122 - accuracy: 0.6288\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 1.1440 - accuracy: 0.6562\n",
      "Generated text after 18 epochs of training:\n",
      "\n",
      " , and speak out tosuitors of his mother her go said to peturn of his own again and caly and by she was at his from them. \n",
      "them for him got him from their own any one will not be and pare, and them for him got him from their own any one will not be and pare, and them for him got him from their own any one will not be and pare, and them for him got him from their own any one will not be and pare, and them for him got him from their own any one will not be and pare, and them for him got him from their own any one will not be and pare, an\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.0766 - accuracy: 0.6781\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.0089 - accuracy: 0.7031\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.9412 - accuracy: 0.7216 0s -\n",
      "Generated text after 21 epochs of training:\n",
      "\n",
      " it is borne\n",
      "in upon me from heaven, and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banquly and seats of a banqul\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.8764 - accuracy: 0.7431\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.8132 - accuracy: 0.7677\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.7554 - accuracy: 0.7855\n",
      "Generated text after 24 epochs of training:\n",
      "\n",
      " aughter of\n",
      "jove, from whatsoever source you may kone offented with minerva said, father, son of saturn, king of kings, it seeps tortheitors them was a foreither of again atlar, and of any one elysses, and she lave he was among them. as soon as on eating him against us for him to took yot it is for theme in atlas, who looks afterbottom of his for to toother sanded to return. now he was among she\n",
      "came in and took of here in atlas, who looks afterbottom of his for to toother sanded to return. now he was among she\n",
      "came in and took of here\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.6991 - accuracy: 0.8027\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.6479 - accuracy: 0.8226\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.5949 - accuracy: 0.8413\n",
      "Generated text after 27 epochs of training:\n",
      "\n",
      " rew brought you to ithaca, and of what neer head canted singing him by friends. it is an island to tell me, and when you have seachron they were\n",
      "come cape and water over her gome by land. tell me and to save his own life and\n",
      "bring himself about his father were cull also a stranger her gome buchter of his own again atlas, who looks afterbottom ofout to she said, father, son of saturn, king of kings, it seepso that he were in him frome, but ther blonzess many on hayssed in seavented means of golden ewer and pare, some men sen he her the\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.5496 - accuracy: 0.8553\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.5018 - accuracy: 0.8732\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.4627 - accuracy: 0.8857\n",
      "Generated text after 30 epochs of training:\n",
      "\n",
      "  him except\n",
      "neptune, who still persecuted him withing about his brave father, and how he is to ithaca, athated he sat among them, he toured of a foreigimacinet his wine and poured it into a silver basing of again to see how he i am goodlen parth himself, and set in asland, for i want\n",
      "to know, are and wat among us seat and tell me true, who you are and where it agamemnon, though he was a foreith then,\n",
      "\n",
      "a mary to all minerva said, father, son of saturn, king of kings, if then, that she might\n",
      "not be annoyed which they had had got sat one\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.4242 - accuracy: 0.8995\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.3915 - accuracy: 0.9091\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.3516 - accuracy: 0.9223\n",
      "Generated text after 33 epochs of training:\n",
      "\n",
      " ir noise and insolence, and that he\n",
      "might ask her rongren, and she\n",
      "darted fromtook of his wife\n",
      "and cantest to mind rither and see how he surititisum; is in and in intringith she can hear any\n",
      "cally him to spears. it is an island to tell castes to and took which they was a fonded bustly her them monger pears went all this is done of goldes oun fathers thinging him betuino sind of golden spear. i his omentembos a forget\n",
      "ulysses than whom they were\n",
      "come about his beanking them flying out against his will. i am no\n",
      "prophet, and she\n",
      "can hear\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.3270 - accuracy: 0.9300\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.3009 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.2808 - accuracy: 0.9420\n",
      "Generated text after 36 epochs of training:\n",
      "\n",
      " ss allgods had now begun to pity him except\n",
      "neptune, who look as oned he sur\n",
      "fettle so lask nevering his dack for them men she dears wing ofteping him esones what i am\n",
      "going to say. singing for awmitt of gold by their sanded to creven len longer leaned them prought them from ever\n",
      "many cone theme were for her fetting home. tell me, and them to warn him enod her flying to save his own life and\n",
      "bring his men safely home; but for have his own life and\n",
      "be honoured as in days gone by. thus brooding as he sat among upcond offen him betuin as\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.2565 - accuracy: 0.9495\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.2315 - accuracy: 0.9589\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.2231 - accuracy: 0.9599\n",
      "Generated text after 39 epochs of training:\n",
      "\n",
      "  not let him\n",
      "get home.\n",
      "\n",
      "now neptune had gone off toeding him against his will. i am no\n",
      "prophet, and know very little about omens, but i speak as it is for ulysses ron ulysses said west ulysses, and keeps trying\n",
      "by sheer will ulysses should get home, we should first send mercury\n",
      "toogher with which she can fly likewind over land or sea; she grasped the\n",
      "redoubtable bronzeshod spear, should be last he could frinds went by, there was inhouse, in a\n",
      "stranger her gillabuth their own folly. look at aegisthus, who still persecuted him withing b\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.2213 - accuracy: 0.9567\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.1866 - accuracy: 0.9715\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1686 - accuracy: 0.9746\n",
      "Generated text after 42 epochs of training:\n",
      "\n",
      " machus saw her long before any one else who does as he did; but\n",
      "aegisthus is no\n",
      "pooking about his vineyard. they told me your\n",
      "father was a footstool also for her feet, and he set\n",
      "another seat near her for himself, about all these things, oh daughter of shem.\n",
      "\n",
      "she havight of pettsing of agains and set cups of gold by their\n",
      "side, and a godd for trew brought you to ithaca, and of what no thas en\n",
      "seefs and cantervant brought them wine and poured it is some ligtren anqo and customs he was acquainted;\n",
      "moreover he suffered much by sea hard g\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.1685 - accuracy: 0.9738\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1586 - accuracy: 0.9757\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.1646 - accuracy: 0.9722\n",
      "Generated text after 45 epochs of training:\n",
      "\n",
      " eaven and earth asunder. this\n",
      "daughter of atlas has got hold of poor unhappy ulysses, and he were with wine\n",
      "and canteth a cargo of iron, and i shall bring back\n",
      "copper.\n",
      "\n",
      "see home, so that he\n",
      "might ask her more freely about his mindry and some cutting up\n",
      "great quantities of meat.\n",
      "\n",
      "telemachus saw her long before any one else who does as he can hear anything about\n",
      "the return of his dear fatherfor this will many coll he sifferings in that lonely seagirt island,\n",
      "far away, poor man, faring by she wast down ane now he can hear anything about\n",
      "\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.1480 - accuracy: 0.9781\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1205 - accuracy: 0.9876\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1300 - accuracy: 0.9831\n",
      "Generated text after 48 epochs of training:\n",
      "\n",
      " pe, who\n",
      "persist in eating up any number of his sheep and oxen; i will embolden him encsewir us\n",
      "gode before them. as soon as he touched his lyre and be hond over; mencery allaca, however, that neptune is still furious with ulysses for having\n",
      "blinded an eye of polyphemus king ofcyclopes. polyphemus is son to\n",
      "neptune bynymph thoosa, daughter toseaking phorcys; there,\n",
      "dish many so reats of iron he would find some means of getting home again. but tell\n",
      "me, and tell me true, who you are and where you come from. tell\n",
      "me of your town and paren\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1238 - accuracy: 0.9841\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0972 - accuracy: 0.9895\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.1050 - accuracy: 0.9854\n",
      "Generated text after 51 epochs of training:\n",
      "\n",
      "  his sufferings in that lonely seagirt island,\n",
      "far away, poor man, from all his friends. it is an island to then, whereon forthwith she was\n",
      "in ithaca, atgateway of ulysses house, disguised as a visitor,\n",
      "mentes, chief oftaphians, and she held a bongo pell me not por himself, whom they compelled pervant brought them wine and poured it is for them.\n",
      "\n",
      "thensuitors came in and took herorbus at heaven, and were and stranging dowe to see\n",
      "many over their hands, and she\n",
      "drew a clean table beside them. an upper servant brought them wine and poure\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.1500 - accuracy: 0.9693\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1818 - accuracy: 0.9545\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1417 - accuracy: 0.9712 0s - l\n",
      "Generated text after 54 epochs of training:\n",
      "\n",
      "  come for.\n",
      "\n",
      "he ledway as he spoke, and minerva followed him. when they were\n",
      "within he took her spear and manner of that was i hone ever\n",
      "then,\n",
      "however, that neptune is still furious with ulysses for having\n",
      "blinded an eye of polyphemus king ofcyclopes. polyphemus is son to\n",
      "neptune bynymph thoosa, daughter toseaking phorcys; therefore\n",
      "though he will not kill ulysses on bean and water over their hands, and she\n",
      "drew a clean table speak of a banquet,\n",
      "so a servant brought a lyre to phemius, whom there compurifiring by seith, and she\n",
      "drew a c\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0933 - accuracy: 0.9879\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0648 - accuracy: 0.9946\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0466 - accuracy: 0.9976\n",
      "Generated text after 57 epochs of training:\n",
      "\n",
      "  will but he would not listen, and now he has paid for\n",
      "everything in full.\n",
      "\n",
      "then minerva said, father, son of saturn, king of kings, if, then, the\n",
      "gods now mean that ulysses should get home, we should first send mercury\n",
      "toogygian island to tell calypso that we have made up our minds and\n",
      "that he is to return. inmeantime i will go to ithaca, to put heart\n",
      "into ulysses son telemachus; i will embolden him to callachaeans\n",
      "in assembly, and speak out tosuitors of his mother went\n",
      "about much himself.\n",
      "\n",
      "and minerva answered, i will tell you truly\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.0380 - accuracy: 0.9981\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0399 - accuracy: 0.9971\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0355 - accuracy: 0.9981\n",
      "Generated text after 60 epochs of training:\n",
      "\n",
      "  to this house, or have you been here in my\n",
      "fathers time? inold days we had many visitors for my father went\n",
      "about much himself.\n",
      "\n",
      "and minerva said, father, son of saturn, king of kings, it served\n",
      "aegisthus right, and so it would any one else who does as he did; but\n",
      "aegisthus is neither here nor there; it is for ulysses that my heart\n",
      "bleeds, when i think of his sufferings in that lonely seagirt island,\n",
      "far away, poor man, from all his friends. it is an island covered\n",
      "with forest, invery middle ofsea, and a goddess lives there,\n",
      "daughter\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.5899 - accuracy: 0.8224\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.4542 - accuracy: 0.8513\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.1587 - accuracy: 0.9622\n",
      "Generated text after 63 epochs of training:\n",
      "\n",
      " \n",
      "in assembly, and speak out tosuitors of his mother went\n",
      "hims. ithatains in culyssent about the surities of meart\n",
      "be, too my folly. look again, and that was why i came, but it seemsgods\n",
      "are still keeping his don are still keeping him from getting home. still, let us lay our heads together and see how\n",
      "we can help him to return; neptune will then be pacified, for if we are\n",
      "all of a mind he can hardly stand out against us.\n",
      "\n",
      "and minerva said, father, son of saturn, king of kings, if, then be pace. a mind oftape, and then himper to tell ca\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.0843 - accuracy: 0.9906\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0517 - accuracy: 0.9970\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0376 - accuracy: 0.9983\n",
      "Generated text after 66 epochs of training:\n",
      "\n",
      " rooding as he sat among them, he\n",
      "caught sight of minerva and went straight togate, for he was vexed\n",
      "that a stranger should be kept waiting for admittance. he took her right\n",
      "hand in his own, and bade her give him her spear. welcome, said he,\n",
      "to our house, and when you have partaken of food you shall tell us what\n",
      "you have come for.\n",
      "\n",
      "he ledway as he spoke, and minerva followed him. when they were\n",
      "within he took her spear and set it inspearstand against a strong\n",
      "bearingpost along withmany other spears of his unhappy father, and\n",
      "he conduct\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0330 - accuracy: 0.9990\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 8s 24ms/step - loss: 0.0293 - accuracy: 0.9990\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 0.0259 - accuracy: 0.9990\n",
      "Generated text after 69 epochs of training:\n",
      "\n",
      " t inspearstand against a strong\n",
      "bearingpost along withmany other spears of his unhappy father, and\n",
      "he crearing about his brave father, and how he would send\n",
      "them flying out ofhouse, if he were to come to his own again and\n",
      "be honoured as in days gone by. thus brooding as he sat among them, he\n",
      "caught sight of minerva and went straight togate, for he was vexed\n",
      "that a stranger should be kept waiting for admittance. he took her right\n",
      "hand in his own, and bade her give him her spear. welcome, said he,\n",
      "to our house, and when you have partake\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.0251 - accuracy: 0.9990\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.1792 - accuracy: 0.9511\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.8118 - accuracy: 0.7540\n",
      "Generated text after 72 epochs of training:\n",
      "\n",
      " ee how\n",
      "we can help him to return; neptune will not be all go and wath him except headed hims with water over over heid you and to pown pheir think of him; frome for. ther pleaging to prevays, who are by sheir\n",
      "exends in frinnd. i ar that he never\n",
      "forthwith she was\n",
      "in ithaca, to put heart\n",
      "into ulysses sure you truw all now,\n",
      "and lives with him? iffored der treat him got sat oned her flean and\n",
      "by him. ther bread, hervants por. when they to peer of minerva and peturn, and to pyep, and he ware with might him. tell me aflas dirtheat as of sh\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.2967 - accuracy: 0.9037\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.1338 - accuracy: 0.9695\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0676 - accuracy: 0.9934\n",
      "Generated text after 75 epochs of training:\n",
      "\n",
      " since that time we have never either of us\n",
      "seenother.\n",
      "\n",
      "my mother, and lienot surgo then,\n",
      "however, when he was among his own people, his troubles were not\n",
      "yet over; nevertheless allgods had now begun to pity him except\n",
      "neptune, who still persecuted him without ceasing and would not let him\n",
      "get home.\n",
      "\n",
      "now neptune had now, are and when ulysses for having\n",
      "blinded an eye of polyphemus king ofcyclopes. polyphemus is son to\n",
      "neptune bynymph thoosa, daughter toseaking phorcys; therefore\n",
      "though he will not kill ulysses outright, he torments him\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.0492 - accuracy: 0.9970\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.0384 - accuracy: 0.9981\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0309 - accuracy: 0.9988\n",
      "Generated text after 78 epochs of training:\n",
      "\n",
      " ca they would pray for longer legs rather\n",
      "than a longer purse, for money would not serve them; but he, alas, has\n",
      "fallen on an ill fate, and even when people do sometimes say that he is\n",
      "coming, we no longer heed them; we shall never see him\n",
      "gods to then,\n",
      "however, when he was among his own people, his troubles were not\n",
      "yet over; nevertheless allgods had now begun to pity him except\n",
      "neptune, who still persecuted him without ceasing and would not let him\n",
      "get home.\n",
      "\n",
      "now neptune had now begun to pity him except\n",
      "neptune, who still persecuted\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.0293 - accuracy: 0.9986\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0481 - accuracy: 0.9965\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.1615 - accuracy: 0.9550\n",
      "Generated text after 81 epochs of training:\n",
      "\n",
      " hey told me your\n",
      "father was at home again, and thinking of aegisth whengods settled that he should go back to ith cantre, and that he will not be offerings to this, and he toremfoceand and see how\n",
      "he not parte and\n",
      "alas, for uforge to here in my\n",
      "fathers time? inold days gell a buch them gold he, daughter tolands withmany other spears of his own any had not be away much longer\n",
      "he dad peeps trying\n",
      "by he would of his will. i among shemar\n",
      "his menting the\n",
      "cattle ofsungod hyperion; sogod here insthat is\n",
      "into a sime west now be all gook all t\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.4922 - accuracy: 0.8405\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.2131 - accuracy: 0.9358\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0966 - accuracy: 0.9803\n",
      "Generated text after 84 epochs of training:\n",
      "\n",
      " me upon us gods for what is after all nothing\n",
      "but their own folly. look at aegisthus; he must needs make love to\n",
      "agamemnons wife unrighteously and then kill agamemnon, though he knew\n",
      "it would bedeath of him; for i sent mercury to warn him not to do\n",
      "either of these things, inasmuch as orestes would be sure to take his\n",
      "revenge when he grew up and wanted to return home. mercury told him\n",
      "this in all good will but he would not listen, and now he has paid for\n",
      "everything in full.\n",
      "\n",
      "then minerva said, father, son of saturn, king of kings, it s\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.0576 - accuracy: 0.9943\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0446 - accuracy: 0.9959\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0325 - accuracy: 0.9982\n",
      "Generated text after 87 epochs of training:\n",
      "\n",
      " ervant brought them bread, and\n",
      "offered them many good things of what there was inhouse,carver\n",
      "fetched them plates of all manner of meats and set cups of gold by their\n",
      "side, and a manservant brought them wine and poures of meats and set cups of gold by their\n",
      "side, and a manservant brought them wine and poures of meats and set cups of gold by their\n",
      "side, and a manservant brought them wine and poures of meats and set cups of gold by their\n",
      "side, and a manservant brought them wine and poures of meats and set cups of gold by their\n",
      "side, and\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.0316 - accuracy: 0.9977\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0268 - accuracy: 0.9985\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0415 - accuracy: 0.9944\n",
      "Generated text after 90 epochs of training:\n",
      "\n",
      " \n",
      "to our house, and when you have partaken of food you shall tell us what reep her long before any one else who does as he did; but\n",
      "aegisthus is neither here nor there; it is for ulysses that my heart\n",
      "bleeds, when i think of his sufferings in that lonely seagirt island,\n",
      "far away, poor man, from all his friends. it is an island covered\n",
      "with forest, invery middle ofsea, and a godd of pathers were friends before us, as old laertes will\n",
      "tell you truly and particularly all about\n",
      "it. i am mentes, son of anchialus, child then brought them wat\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 0.4247 - accuracy: 0.8670\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.3956 - accuracy: 0.8703\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.1508 - accuracy: 0.9590\n",
      "Generated text after 93 epochs of training:\n",
      "\n",
      " mixing wine with water inmixingbowls, some cleaning down the\n",
      "tables with wet sponges and laying them out against us.\n",
      "\n",
      "and minerva said, father, son of saturn, king of kings, it servafate, far having\n",
      "blinded an eye of polyphemus king ofcyclopes. polyphemus is son to\n",
      "neptune bynymph thoosa, had eare not be away much\n",
      "longer; for he is a man of such resource that even though he were in\n",
      "chains of iron he would find some means of getting home again. but tell\n",
      "me, and tell me true, can ulysses really have such a fine looking fellow\n",
      "for a son?\n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0822 - accuracy: 0.9866\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0493 - accuracy: 0.9956\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0349 - accuracy: 0.9976\n",
      "Generated text after 96 epochs of training:\n",
      "\n",
      " in tired from pottering about his vineyard. they told me your\n",
      "father was at home again, and that was why i came, but it seemsgods\n",
      "are still keeping him back, for he is not dead yet not onmainland.\n",
      "it is more likely he is on some seagirt island in mid ocean, or a\n",
      "prisoner among savages who are detaining him against his will. i am no\n",
      "prophet, and know very little about omens, but i speak as it is borne\n",
      "in upon me from heaven, and set cus of foll you tome however chear to then keeptool that even though he were in\n",
      "chains of iron he would \n",
      "Epoch 1/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0292 - accuracy: 0.9979\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 0.0290 - accuracy: 0.9975\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 0.0249 - accuracy: 0.9980\n",
      "Generated text after 99 epochs of training:\n",
      "\n",
      " anchialus, and i am king oftaphians. i have\n",
      "come here with my ship and crew, on a voyage to men of a foreign tongue\n",
      "being bound for temesa with a cargo of iron, and i shall bring back\n",
      "copper. as for my ship, it lies over yonder offopen country away\n",
      "fromtown, inharbour rheithron underwooded mountain\n",
      "neritum. our fathers were friends before us, as old laertes will\n",
      "tell you, if you will go and ask him. they say, however, that he never\n",
      "comes to town now, and lives by himself incountry, faring hardly,\n",
      "with an old woman to look after him an\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs_to_train = 20\n",
    "\n",
    "for i in range(epochs_to_train, epochs+1, epochs_to_train):\n",
    "    # Fit model for 3 epochs\n",
    "    model.fit(X_data, y_data, batch_size=batch_size, epochs=epochs_to_train)\n",
    "\n",
    "    # Set random seed sequence and generated text string\n",
    "    seed_sequence = random.choice(X_data)\n",
    "    generated_text = ''.join([str(vocab[ind]) for ind in seed_sequence])\n",
    "\n",
    "    for _ in range(500):\n",
    "        # Predict most probable index and its corresponding character\n",
    "        predicted_ind = int(np.argmax(model.predict([seed_sequence])))\n",
    "        predicted_char = vocab[predicted_ind]\n",
    "\n",
    "        # Update generated text and seed sequence\n",
    "        generated_text = ''.join((generated_text, predicted_char))\n",
    "        del seed_sequence[0]\n",
    "        seed_sequence.append(predicted_ind)\n",
    "\n",
    "    # Print generated text every iteration\n",
    "    print(f\"Generated text after {i} epochs of training:\\n\\n\", \n",
    "        generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchialus, and i am king oftaphians. i have\n",
      "come here with my ship and crew, on a voyage to men of a foreign tongue\n",
      "being bound for temesa with a cargo of iron, and i shall bring back\n",
      "copper. as for my ship, it lies over yonder offopen country away\n",
      "fromtown, inharbour rheithron underwooded mountain\n",
      "neritum. our fathers were friends before us, as old laertes will\n",
      "tell you, if you will go and ask him. they say, however, that he never\n",
      "comes to town now, and lives by himself incountry, faring hardly,\n",
      "with an old woman to look after him an\n"
     ]
    }
   ],
   "source": [
    "# Print final generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Repeat your experiment using a GRU layer\n",
    "\n",
    "Repeat tasks 3 and 4 with the GRU layer in place of the LSTM. Do you notice any differences in the performance, training, or text generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#4863A0'>A neural network with GRU layers was generally trained faster than with LSTM on a particular dataset. However, both options showed fairly good predictive ability. It was clear that the first iterations of training the model got stuck on some phrases, but with further training it could generate more and more adequate texts.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with sequences of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "text = preprocess_file(corpus_file)\n",
    "text = text[:500000]\n",
    "\n",
    "# Transform text to sequence of sentences\n",
    "text_to_sentences = [sen.split() for sen in text.split('.')]\n",
    "\n",
    "# Build dictionary of indices\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_to_sentences)\n",
    "\n",
    "# Change texts into sequence of indexes\n",
    "text_numeric = tokenizer.texts_to_sequences(text_to_sentences)\n",
    "\n",
    "# Find vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences\n",
    "pad_length = 7\n",
    "text_pad = pad_sequences(text_numeric, pad_length)\n",
    "\n",
    "# Create list of next words\n",
    "next_words = np.append(np.asarray([elem[0] for elem in text_pad[1:]]), 0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 7, 3000)           32964000  \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               1201920   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10988)             1417452   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,583,372\n",
      "Trainable params: 35,583,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize model object\n",
    "model_words = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model_words.add(layers.Embedding(input_dim=vocab_size, output_dim=3000, \n",
    "        trainable=True, input_length=pad_length))\n",
    "model_words.add(layers.GRU(rnn_units, return_sequences=False))\n",
    "model_words.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_words.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print summary of compiled model\n",
    "model_words.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "755/755 [==============================] - 240s 316ms/step - loss: 7.5367 - accuracy: 0.0580\n",
      "Epoch 2/10\n",
      "755/755 [==============================] - 239s 317ms/step - loss: 5.8394 - accuracy: 0.0616\n",
      "Epoch 3/10\n",
      "755/755 [==============================] - 238s 315ms/step - loss: 4.7190 - accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "755/755 [==============================] - 235s 311ms/step - loss: 3.4724 - accuracy: 0.2991\n",
      "Epoch 5/10\n",
      "755/755 [==============================] - 244s 323ms/step - loss: 2.1745 - accuracy: 0.6035\n",
      "Epoch 6/10\n",
      "755/755 [==============================] - 238s 315ms/step - loss: 1.1561 - accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "755/755 [==============================] - 240s 319ms/step - loss: 0.5489 - accuracy: 0.9427\n",
      "Epoch 8/10\n",
      "755/755 [==============================] - 239s 317ms/step - loss: 0.2675 - accuracy: 0.9612\n",
      "Epoch 9/10\n",
      "755/755 [==============================] - 231s 306ms/step - loss: 0.1743 - accuracy: 0.9662\n",
      "Epoch 10/10\n",
      "755/755 [==============================] - 228s 303ms/step - loss: 0.1274 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4285aa610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model_words.fit(text_pad, next_words, batch_size=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "\n",
      " laid it down ondeck of the ship theoclymenus she to to to to to to by cover no she who on on on went somebody may heaven warm help come wretches andsheep wind away away away away away away give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give give\n"
     ]
    }
   ],
   "source": [
    "# Set random seed sequence and generated text string\n",
    "seed_sequence = random.choice(text_pad).reshape(1, -1)\n",
    "generated_text = ' '.join([tokenizer.index_word.get(ind, str(0)) for ind in seed_sequence[0]])\n",
    "\n",
    "for _ in range(100):\n",
    "    # Predict most probable index and its corresponding word\n",
    "    predicted_ind = np.argmax(model_words.predict(seed_sequence))\n",
    "    predicted_word = tokenizer.index_word.get(predicted_ind, 0)\n",
    "    \n",
    "    # Update generated text and seed sequence\n",
    "    generated_text = ' '.join((generated_text, str(predicted_word)))\n",
    "    seed_sequence = np.append(np.delete(seed_sequence, 0), predicted_ind).reshape(1, -1)\n",
    "\n",
    "# Print generated text every iteration\n",
    "print(f\"Generated text:\\n\\n\", \n",
    "    generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#4863A0'>As can be seen, the model failed to produce an adequate text, despite good accuracy in the training set. This suggests that it is worth using a more complex and refined model with several layers and dropouts, as well as preprocessing the entire text in more detail.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "This exercise was a small taste of the power of RNN models. Here are some other things you can try if you want to go further with the time you have left.\n",
    "\n",
    "- Sample the output distribution from the model to generate the next character in the sequence (instead of taking the most probable). This will add some more randomness to your text generation.\n",
    "- Build a vocabulary of words, rather than characters. This will highlight the importance of the embedding layer (you will need to use a smaller output dimension for the embedding than the vocabulary size).\n",
    "- Try other media types (eg: sound, video, guitar tabs...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
